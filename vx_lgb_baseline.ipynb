{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import gc\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from lightgbm.sklearn import LGBMClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem(df):\n",
    "    start_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "    end_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    print('{:.2f} Mb, {:.2f} Mb ({:.2f} %)'.format(start_mem, end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    gc.collect()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import njit\n",
    "from scipy.stats import rankdata\n",
    "\n",
    "@njit\n",
    "def _auc(actual, pred_ranks):\n",
    "    actual = np.asarray(actual)\n",
    "    pred_ranks = np.asarray(pred_ranks)\n",
    "    n_pos = np.sum(actual)\n",
    "    n_neg = len(actual) - n_pos\n",
    "    return (np.sum(pred_ranks[actual==1]) - n_pos*(n_pos+1)/2) / (n_pos*n_neg)\n",
    "\n",
    "def auc(actual, predicted):\n",
    "    pred_ranks = rankdata(predicted)\n",
    "    return _auc(actual, pred_ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uAUC(labels, preds):\n",
    "    \"\"\"Calculate user AUC\"\"\"\n",
    "    size = 0\n",
    "    \n",
    "    total_auc = 0\n",
    "    \n",
    "    for user_id in list(usefulid):\n",
    "        auc1 = auc(labels[userid_dict[user_id]], preds[userid_dict[user_id]])\n",
    "        total_auc += auc1\n",
    "        size += 1.0\n",
    "    user_auc = float(total_auc)/size\n",
    "    return user_auc\n",
    "\n",
    "def custom_uAUC_eval(y_true, y_pred):\n",
    "    eval_auc = uAUC(y_true,y_pred)\n",
    "    return \"uAUC\", eval_auc, True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_history_stats(data,ycols,gap):\n",
    "    for f in [['userid','authorid','feedid']]:\n",
    "        res = pd.DataFrame()\n",
    "        for day_id in range(1+gap,16):\n",
    "            print('*************************** start {} ***************************'.format(day_id))\n",
    "            tmp_data = data[(data['day']<day_id)& (data['day']>=day_id - gap)][f +['id','day','stay','play']+ ycols].copy()\n",
    "            res_data = data[(data['day']==day_id)][f + ['day']].drop_duplicates()\n",
    "            \n",
    "            tmp = tmp_data[f + ['id']].groupby(f,as_index = False)['id'].agg({'_'.join(f) + '_prev_{}day_count'.format(gap):'count'})\n",
    "            tmp['day'] = day_id\n",
    "            res_data = res_data.merge(tmp,on = f + ['day'],how = 'left')\n",
    "            \n",
    "\n",
    "            tmp = tmp_data[f + ['id','stay']].groupby(f,as_index = False)['stay'].agg({'_'.join(f) + '_prev_{}day_stay_mean'.format(gap):'mean'})\n",
    "            tmp['day'] = day_id\n",
    "            res_data = res_data.merge(tmp,on = f + ['day'],how = 'left')\n",
    "            \n",
    "\n",
    "            tmp = tmp_data[f + ['id','play']].groupby(f,as_index = False)['play'].agg({'_'.join(f) + '_prev_{}day_play_mean'.format(gap):'mean'})\n",
    "            tmp['day'] = day_id\n",
    "            res_data = res_data.merge(tmp,on = f + ['day'],how = 'left')\n",
    "            \n",
    "            \n",
    "            \n",
    "            for ycol in ycols:\n",
    "                click_df = tmp_data[tmp_data[ycol] ==1].reset_index(drop = True)\n",
    "\n",
    "\n",
    "                tmp = click_df[f + ['id']].groupby(f, as_index=False)['id'].agg({'_'.join(f) + '_prev_{}day_{}_count'.format(gap,ycol): 'count'})\n",
    "                tmp['day']  = day_id\n",
    "\n",
    "                res_data = res_data.merge(tmp, on=f + ['day'], how='left')\n",
    "                \n",
    "                res_data['_'.join(f) + '_prev_{}day_{}_count'.format(gap,ycol)] = res_data['_'.join(f) + '_prev_{}day_{}_count'.format(gap,ycol)].fillna(0)\n",
    "                \n",
    "        \n",
    "\n",
    "                res_data['_'.join(f) + '_prev_{}day_{}_ratio'.format(gap,ycol)] = res_data['_'.join(f) + '_prev_{}day_{}_count'.format(gap,ycol)] / (\n",
    "                    res_data['_'.join(f) + '_prev_{}day_count'.format(gap)] + res_data['_'.join(f) + '_prev_{}day_count'.format(gap)].mean())  \n",
    "        \n",
    "            res= pd.concat([res,res_data])\n",
    "        \n",
    "        data = data.merge(res,on = f + ['day'],how = 'left')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf(input_values, output_num, output_prefix, seed=1024):\n",
    "    tfidf_enc = TfidfVectorizer()\n",
    "    tfidf_vec = tfidf_enc.fit_transform(input_values)\n",
    "    svd_tmp = TruncatedSVD(n_components=output_num, n_iter=20, random_state=seed)\n",
    "    svd_tmp = svd_tmp.fit_transform(tfidf_vec)\n",
    "    svd_tmp = pd.DataFrame(svd_tmp)\n",
    "    svd_tmp.columns = ['{}_tfidf_{}'.format(output_prefix, i) for i in range(output_num)]\n",
    "    return svd_tmp\n",
    "\n",
    "\n",
    "def count2vec(input_values, output_num, output_prefix, seed=1024):\n",
    "    count_enc = CountVectorizer()\n",
    "    count_vec = count_enc.fit_transform(input_values)\n",
    "    svd_tmp = TruncatedSVD(n_components=output_num, n_iter=20, random_state=seed)\n",
    "    svd_tmp = svd_tmp.fit_transform(count_vec)\n",
    "    svd_tmp = pd.DataFrame(svd_tmp)\n",
    "    svd_tmp.columns = ['{}_countvec_{}'.format(output_prefix, i) for i in range(output_num)]\n",
    "    return svd_tmp\n",
    "\n",
    "def get_tfidf_count_vec(feed,group_id,group_target,num):\n",
    "    tmp = feed[[group_id,group_target]]\n",
    "    tfidf_tmp = tfidf(tmp[group_target], 4, group_target)\n",
    "    count_tmp = count2vec(tmp[group_target], 4, group_target)\n",
    "    return pd.concat([tmp[group_id], tfidf_tmp, count_tmp], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************load_data***********************\n",
      "*********************Finish***********************\n"
     ]
    }
   ],
   "source": [
    "print(\"*********************{}***********************\".format('load_data'))\n",
    "PATH = 'wx/wechat_algo_data1/'\n",
    "feed_embeddings = pd.read_csv(PATH + \"feed_embeddings.csv\")\n",
    "feed_info = pd.read_csv(PATH + \"feed_info.csv\")\n",
    "sample = pd.read_csv(PATH + \"submit_demo_初赛a.csv\")\n",
    "test_a = pd.read_csv(PATH + \"test_a.csv\")\n",
    "user_action = pd.read_csv(PATH + \"user_action.csv\")\n",
    "\n",
    "user_action.columns = ['userid', 'feedid', 'day', 'device', 'read_comment', 'comment','like', 'play', 'stay', 'click_avatar', 'forward', 'follow','favorite']\n",
    "\n",
    "\n",
    "test_a['day'] = 15\n",
    "data = pd.concat([user_action,test_a])\n",
    "data = data.reset_index(drop = True)\n",
    "data['id'] =data.index +1\n",
    "\n",
    "data = data.merge(feed_info[['feedid','authorid','videoplayseconds','bgm_song_id', 'bgm_singer_id']],on = 'feedid',how = 'left')\n",
    "\n",
    "print(\"*********************{}***********************\".format('Finish'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************get_history_fea***********************\n",
      "*************************** start 2 ***************************\n",
      "*************************** start 3 ***************************\n",
      "*************************** start 4 ***************************\n",
      "*************************** start 5 ***************************\n",
      "*************************** start 6 ***************************\n",
      "*************************** start 7 ***************************\n",
      "*************************** start 8 ***************************\n",
      "*************************** start 9 ***************************\n",
      "*************************** start 10 ***************************\n",
      "*************************** start 11 ***************************\n",
      "*************************** start 12 ***************************\n",
      "*************************** start 13 ***************************\n",
      "*************************** start 14 ***************************\n",
      "*************************** start 15 ***************************\n",
      "*************************** start 4 ***************************\n",
      "*************************** start 5 ***************************\n",
      "*************************** start 6 ***************************\n",
      "*************************** start 7 ***************************\n",
      "*************************** start 8 ***************************\n",
      "*************************** start 9 ***************************\n",
      "*************************** start 10 ***************************\n",
      "*************************** start 11 ***************************\n",
      "*************************** start 12 ***************************\n",
      "*************************** start 13 ***************************\n",
      "*************************** start 14 ***************************\n",
      "*************************** start 15 ***************************\n",
      "*************************** start 8 ***************************\n",
      "*************************** start 9 ***************************\n",
      "*************************** start 10 ***************************\n",
      "*************************** start 11 ***************************\n",
      "*************************** start 12 ***************************\n",
      "*************************** start 13 ***************************\n",
      "*************************** start 14 ***************************\n",
      "*************************** start 15 ***************************\n",
      "*********************Finish***********************\n"
     ]
    }
   ],
   "source": [
    "print(\"*********************{}***********************\".format('get_history_fea'))\n",
    "for gap in [1,3,7]:\n",
    "    data = get_history_stats(data,['read_comment', 'comment','like', 'click_avatar', 'forward', 'follow','favorite'],gap)\n",
    "    \n",
    "print(\"*********************{}***********************\".format('Finish'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************get_first_keyword***********************\n",
      "*********************get_first_tag***********************\n",
      "*********************Finish***********************\n"
     ]
    }
   ],
   "source": [
    "print(\"*********************{}***********************\".format('get_first_keyword'))\n",
    "feed_info['manual_keyword_list'] = feed_info['manual_keyword_list'].fillna(';')\n",
    "feed_info['manual_keword'] = feed_info['manual_keyword_list'].apply(lambda x:x.split(';')[0]).fillna(-1)\n",
    "feed_info['manual_keword'] = feed_info['manual_keword'].replace('','-1').astype(int)\n",
    "\n",
    "print(\"*********************{}***********************\".format('get_first_tag'))\n",
    "feed_info['manual_tag_list'] = feed_info['manual_tag_list'].fillna(';')\n",
    "feed_info['manual_tag'] = feed_info['manual_tag_list'].apply(lambda x:x.split(';')[0]).fillna(-1)\n",
    "feed_info['manual_tag'] = feed_info['manual_tag'].replace('','-1').astype(int)\n",
    "\n",
    "data = data.merge(feed_info[['feedid','manual_keword','manual_tag']],on = 'feedid',how = 'left')\n",
    "print(\"*********************{}***********************\".format('Finish'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************tfidf_fea***********************\n",
      "description\n",
      "ocr\n",
      "asr\n",
      "*********************Finish***********************\n"
     ]
    }
   ],
   "source": [
    "print(\"*********************{}***********************\".format('tfidf_fea'))\n",
    "\n",
    "for group_target in ['description','ocr','asr']:#,'description_char','ocr_char','asr_char']:\n",
    "    print(group_target)\n",
    "    feed_info[group_target]  = feed_info[group_target].fillna('')\n",
    "    data = data.merge(get_tfidf_count_vec(feed_info,'feedid',group_target,4),on = 'feedid',how = 'left')\n",
    "    \n",
    "print(\"*********************{}***********************\".format('Finish'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************count_fea***********************\n",
      "*********************Finish***********************\n",
      "*********************cross_fea***********************\n",
      "*********************Finish***********************\n"
     ]
    }
   ],
   "source": [
    "print(\"*********************{}***********************\".format('count_fea'))\n",
    "cate_cols = ['userid','feedid','authorid','bgm_song_id', 'bgm_singer_id','videoplayseconds','manual_keword','manual_tag']\n",
    "for f in cate_cols:\n",
    "    data[f] = data[f].fillna(-1).astype(int)\n",
    "    data[f + '_count'] = data[f].map(data[f].value_counts())\n",
    "\n",
    "print(\"*********************{}***********************\".format('Finish'))\n",
    "\n",
    "\n",
    "print(\"*********************{}***********************\".format('cross_fea'))\n",
    "for f in ['feedid','authorid','bgm_song_id', 'bgm_singer_id','videoplayseconds','manual_keword','manual_tag']:\n",
    "    data['user_{}_nunique'.format(f)] = data.groupby('userid')[f].transform('nunique')\n",
    "    data['{}_user_nunique'.format(f)] = data.groupby(f)['userid'].transform('nunique')\n",
    "\n",
    "    \n",
    "print(\"*********************{}***********************\".format('Finish'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================================================\n",
      "========================================================================================================\n"
     ]
    }
   ],
   "source": [
    "print('========================================================================================================')\n",
    "train_df = data[data['read_comment'].notna()].reset_index(drop=True)\n",
    "test_df = data[data['read_comment'].isna()].reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "labels = train_df[['read_comment', 'like', 'click_avatar', 'forward']]\n",
    "\n",
    "\n",
    "train_idx = train_df[(train_df['day'] < 14)].index.tolist()\n",
    "\n",
    "\n",
    "val_idx = train_df[train_df['day']  >= 14].index.tolist()\n",
    "\n",
    "\n",
    "gc.collect()\n",
    "print('========================================================================================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106\n",
      "['userid', 'feedid', 'device', 'authorid', 'videoplayseconds', 'bgm_song_id', 'bgm_singer_id', 'userid_authorid_feedid_prev_1day_count', 'userid_authorid_feedid_prev_1day_stay_mean', 'userid_authorid_feedid_prev_1day_play_mean', 'userid_authorid_feedid_prev_1day_read_comment_count', 'userid_authorid_feedid_prev_1day_read_comment_ratio', 'userid_authorid_feedid_prev_1day_comment_count', 'userid_authorid_feedid_prev_1day_comment_ratio', 'userid_authorid_feedid_prev_1day_like_count', 'userid_authorid_feedid_prev_1day_like_ratio', 'userid_authorid_feedid_prev_1day_click_avatar_count', 'userid_authorid_feedid_prev_1day_click_avatar_ratio', 'userid_authorid_feedid_prev_1day_forward_count', 'userid_authorid_feedid_prev_1day_forward_ratio', 'userid_authorid_feedid_prev_1day_follow_count', 'userid_authorid_feedid_prev_1day_follow_ratio', 'userid_authorid_feedid_prev_1day_favorite_count', 'userid_authorid_feedid_prev_1day_favorite_ratio', 'userid_authorid_feedid_prev_3day_count', 'userid_authorid_feedid_prev_3day_stay_mean', 'userid_authorid_feedid_prev_3day_play_mean', 'userid_authorid_feedid_prev_3day_read_comment_count', 'userid_authorid_feedid_prev_3day_read_comment_ratio', 'userid_authorid_feedid_prev_3day_comment_count', 'userid_authorid_feedid_prev_3day_comment_ratio', 'userid_authorid_feedid_prev_3day_like_count', 'userid_authorid_feedid_prev_3day_like_ratio', 'userid_authorid_feedid_prev_3day_click_avatar_count', 'userid_authorid_feedid_prev_3day_click_avatar_ratio', 'userid_authorid_feedid_prev_3day_forward_count', 'userid_authorid_feedid_prev_3day_forward_ratio', 'userid_authorid_feedid_prev_3day_follow_count', 'userid_authorid_feedid_prev_3day_follow_ratio', 'userid_authorid_feedid_prev_3day_favorite_count', 'userid_authorid_feedid_prev_3day_favorite_ratio', 'userid_authorid_feedid_prev_7day_count', 'userid_authorid_feedid_prev_7day_stay_mean', 'userid_authorid_feedid_prev_7day_play_mean', 'userid_authorid_feedid_prev_7day_read_comment_count', 'userid_authorid_feedid_prev_7day_read_comment_ratio', 'userid_authorid_feedid_prev_7day_comment_count', 'userid_authorid_feedid_prev_7day_comment_ratio', 'userid_authorid_feedid_prev_7day_like_count', 'userid_authorid_feedid_prev_7day_like_ratio', 'userid_authorid_feedid_prev_7day_click_avatar_count', 'userid_authorid_feedid_prev_7day_click_avatar_ratio', 'userid_authorid_feedid_prev_7day_forward_count', 'userid_authorid_feedid_prev_7day_forward_ratio', 'userid_authorid_feedid_prev_7day_follow_count', 'userid_authorid_feedid_prev_7day_follow_ratio', 'userid_authorid_feedid_prev_7day_favorite_count', 'userid_authorid_feedid_prev_7day_favorite_ratio', 'manual_keword', 'manual_tag', 'description_tfidf_0', 'description_tfidf_1', 'description_tfidf_2', 'description_tfidf_3', 'description_countvec_0', 'description_countvec_1', 'description_countvec_2', 'description_countvec_3', 'ocr_tfidf_0', 'ocr_tfidf_1', 'ocr_tfidf_2', 'ocr_tfidf_3', 'ocr_countvec_0', 'ocr_countvec_1', 'ocr_countvec_2', 'ocr_countvec_3', 'asr_tfidf_0', 'asr_tfidf_1', 'asr_tfidf_2', 'asr_tfidf_3', 'asr_countvec_0', 'asr_countvec_1', 'asr_countvec_2', 'asr_countvec_3', 'userid_count', 'feedid_count', 'authorid_count', 'bgm_song_id_count', 'bgm_singer_id_count', 'videoplayseconds_count', 'manual_keword_count', 'manual_tag_count', 'user_feedid_nunique', 'feedid_user_nunique', 'user_authorid_nunique', 'authorid_user_nunique', 'user_bgm_song_id_nunique', 'bgm_song_id_user_nunique', 'user_bgm_singer_id_nunique', 'bgm_singer_id_user_nunique', 'user_videoplayseconds_nunique', 'videoplayseconds_user_nunique', 'user_manual_keword_nunique', 'manual_keword_user_nunique', 'user_manual_tag_nunique', 'manual_tag_user_nunique']\n"
     ]
    }
   ],
   "source": [
    "used_feat = [f for f in train_df.columns if f not in (['day','read_comment','comment','like','play','stay','click_avatar','forward','follow','favorite','id'])]\n",
    "print(len(used_feat))\n",
    "print(used_feat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's auc: 0.908964\tvalid_0's uAUC: 0.59723\n",
      "[100]\tvalid_0's auc: 0.919483\tvalid_0's uAUC: 0.610154\n",
      "[150]\tvalid_0's auc: 0.924215\tvalid_0's uAUC: 0.616733\n",
      "[200]\tvalid_0's auc: 0.92663\tvalid_0's uAUC: 0.622169\n",
      "[250]\tvalid_0's auc: 0.928259\tvalid_0's uAUC: 0.627538\n",
      "[300]\tvalid_0's auc: 0.929194\tvalid_0's uAUC: 0.630371\n",
      "[350]\tvalid_0's auc: 0.929778\tvalid_0's uAUC: 0.631716\n",
      "[400]\tvalid_0's auc: 0.930285\tvalid_0's uAUC: 0.633311\n",
      "[450]\tvalid_0's auc: 0.93063\tvalid_0's uAUC: 0.634656\n",
      "[500]\tvalid_0's auc: 0.930916\tvalid_0's uAUC: 0.635532\n",
      "[550]\tvalid_0's auc: 0.931086\tvalid_0's uAUC: 0.635864\n",
      "[600]\tvalid_0's auc: 0.931278\tvalid_0's uAUC: 0.636127\n",
      "[650]\tvalid_0's auc: 0.93143\tvalid_0's uAUC: 0.636631\n",
      "[700]\tvalid_0's auc: 0.931492\tvalid_0's uAUC: 0.637257\n",
      "[750]\tvalid_0's auc: 0.931561\tvalid_0's uAUC: 0.638254\n",
      "[800]\tvalid_0's auc: 0.931573\tvalid_0's uAUC: 0.63906\n",
      "[850]\tvalid_0's auc: 0.931667\tvalid_0's uAUC: 0.639348\n",
      "[900]\tvalid_0's auc: 0.931697\tvalid_0's uAUC: 0.640001\n",
      "[950]\tvalid_0's auc: 0.931751\tvalid_0's uAUC: 0.640133\n",
      "[1000]\tvalid_0's auc: 0.931835\tvalid_0's uAUC: 0.640014\n",
      "[1050]\tvalid_0's auc: 0.931878\tvalid_0's uAUC: 0.640379\n",
      "[1100]\tvalid_0's auc: 0.931851\tvalid_0's uAUC: 0.64033\n",
      "[1150]\tvalid_0's auc: 0.931865\tvalid_0's uAUC: 0.639792\n",
      "[1200]\tvalid_0's auc: 0.931878\tvalid_0's uAUC: 0.640219\n",
      "[1250]\tvalid_0's auc: 0.932036\tvalid_0's uAUC: 0.6404\n",
      "Early stopping, best iteration is:\n",
      "[1063]\tvalid_0's auc: 0.931868\tvalid_0's uAUC: 0.640608\n",
      "uAUC_score 0.6406080087450254\n",
      "1063\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's auc: 0.812448\tvalid_0's uAUC: 0.602806\n",
      "[100]\tvalid_0's auc: 0.822806\tvalid_0's uAUC: 0.616757\n",
      "[150]\tvalid_0's auc: 0.829507\tvalid_0's uAUC: 0.621433\n",
      "[200]\tvalid_0's auc: 0.833197\tvalid_0's uAUC: 0.624689\n",
      "[250]\tvalid_0's auc: 0.835416\tvalid_0's uAUC: 0.627151\n",
      "[300]\tvalid_0's auc: 0.836967\tvalid_0's uAUC: 0.62785\n",
      "[350]\tvalid_0's auc: 0.838004\tvalid_0's uAUC: 0.628551\n",
      "[400]\tvalid_0's auc: 0.838651\tvalid_0's uAUC: 0.62958\n",
      "[450]\tvalid_0's auc: 0.839094\tvalid_0's uAUC: 0.630526\n",
      "[500]\tvalid_0's auc: 0.839412\tvalid_0's uAUC: 0.631273\n",
      "[550]\tvalid_0's auc: 0.839559\tvalid_0's uAUC: 0.630956\n",
      "[600]\tvalid_0's auc: 0.839766\tvalid_0's uAUC: 0.631404\n",
      "[650]\tvalid_0's auc: 0.839879\tvalid_0's uAUC: 0.63155\n",
      "[700]\tvalid_0's auc: 0.84002\tvalid_0's uAUC: 0.631973\n",
      "[750]\tvalid_0's auc: 0.839922\tvalid_0's uAUC: 0.631969\n",
      "[800]\tvalid_0's auc: 0.839869\tvalid_0's uAUC: 0.63168\n",
      "[850]\tvalid_0's auc: 0.839835\tvalid_0's uAUC: 0.631514\n",
      "Early stopping, best iteration is:\n",
      "[693]\tvalid_0's auc: 0.840053\tvalid_0's uAUC: 0.63187\n",
      "uAUC_score 0.6318700171638456\n",
      "693\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's auc: 0.827872\tvalid_0's uAUC: 0.703623\n",
      "[100]\tvalid_0's auc: 0.838471\tvalid_0's uAUC: 0.713347\n",
      "[150]\tvalid_0's auc: 0.843127\tvalid_0's uAUC: 0.718078\n",
      "[200]\tvalid_0's auc: 0.845792\tvalid_0's uAUC: 0.71987\n",
      "[250]\tvalid_0's auc: 0.847222\tvalid_0's uAUC: 0.721041\n",
      "[300]\tvalid_0's auc: 0.848705\tvalid_0's uAUC: 0.721243\n",
      "[350]\tvalid_0's auc: 0.8497\tvalid_0's uAUC: 0.722405\n",
      "[400]\tvalid_0's auc: 0.850343\tvalid_0's uAUC: 0.722179\n",
      "[450]\tvalid_0's auc: 0.850704\tvalid_0's uAUC: 0.722225\n",
      "[500]\tvalid_0's auc: 0.851219\tvalid_0's uAUC: 0.722339\n",
      "[550]\tvalid_0's auc: 0.851609\tvalid_0's uAUC: 0.722668\n",
      "[600]\tvalid_0's auc: 0.851665\tvalid_0's uAUC: 0.72186\n",
      "[650]\tvalid_0's auc: 0.851784\tvalid_0's uAUC: 0.721179\n",
      "[700]\tvalid_0's auc: 0.851798\tvalid_0's uAUC: 0.721456\n",
      "[750]\tvalid_0's auc: 0.851833\tvalid_0's uAUC: 0.722001\n",
      "Early stopping, best iteration is:\n",
      "[575]\tvalid_0's auc: 0.851691\tvalid_0's uAUC: 0.722845\n",
      "uAUC_score 0.7228454645887562\n",
      "575\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[50]\tvalid_0's auc: 0.848373\tvalid_0's uAUC: 0.689249\n",
      "[100]\tvalid_0's auc: 0.856845\tvalid_0's uAUC: 0.699393\n",
      "[150]\tvalid_0's auc: 0.860446\tvalid_0's uAUC: 0.700456\n",
      "[200]\tvalid_0's auc: 0.862459\tvalid_0's uAUC: 0.704634\n",
      "[250]\tvalid_0's auc: 0.863397\tvalid_0's uAUC: 0.707502\n",
      "[300]\tvalid_0's auc: 0.862967\tvalid_0's uAUC: 0.707116\n",
      "[350]\tvalid_0's auc: 0.86173\tvalid_0's uAUC: 0.705152\n",
      "[400]\tvalid_0's auc: 0.861036\tvalid_0's uAUC: 0.704009\n",
      "[450]\tvalid_0's auc: 0.860291\tvalid_0's uAUC: 0.703795\n",
      "Early stopping, best iteration is:\n",
      "[251]\tvalid_0's auc: 0.863463\tvalid_0's uAUC: 0.707626\n",
      "uAUC_score 0.7076263097224081\n",
      "251\n"
     ]
    }
   ],
   "source": [
    "cate_cols = [ 'userid','feedid','authorid','bgm_song_id', 'bgm_singer_id','manual_keword','manual_keword','manual_tag']\n",
    "\n",
    "df_oof = train_df[['userid', 'read_comment', 'comment', 'like', 'click_avatar', 'forward', 'follow', 'favorite']].iloc[val_idx].reset_index(drop = True)\n",
    "df_oof['id'] = df_oof.index\n",
    "temp = df_oof.groupby(['userid'])['id'].apply(lambda x:np.array(x)).reset_index()\n",
    "userid_dict =  dict(zip(temp['userid'].to_list(), temp['id'].to_list()))\n",
    "\n",
    "best_rounds_list = []\n",
    "df_importance_list = []\n",
    "\n",
    "for ycol in  [ 'read_comment','like', 'click_avatar', 'forward']:\n",
    "    train_x = train_df[used_feat].iloc[train_idx].reset_index(drop=True)\n",
    "    train_y = labels[ycol][train_idx]\n",
    "    val_x = train_df[used_feat].iloc[val_idx].reset_index(drop=True)\n",
    "    val_y = labels[ycol][val_idx]\n",
    "    \n",
    "    df_oof[ycol] = df_oof[ycol].astype(int)\n",
    "    tt = df_oof.groupby(['userid'])[ycol].agg({'mean'}).reset_index()\n",
    "    usefulid = set(tt['userid']) - set(tt[tt['mean'].isin([0,1])]['userid'])\n",
    "    \n",
    "    clf = LGBMClassifier(\n",
    "        learning_rate = 0.05,\n",
    "        n_estimators = 10000000,\n",
    "        num_leaves = 32,\n",
    "        subsample = 0.9,\n",
    "        colsample_bytree = 0.8,\n",
    "        random_state = 2019,\n",
    "        metric = 'auc'\n",
    "    )\n",
    "\n",
    "    #train\n",
    "    clf.fit(\n",
    "        train_x,train_y,\n",
    "        eval_set = [(val_x,val_y)],\n",
    "        eval_metric=lambda y_true, y_pred: [custom_uAUC_eval(y_true, y_pred)],\n",
    "        #eval_metric='auc',\n",
    "        categorical_feature = cate_cols,\n",
    "        early_stopping_rounds = 200,\n",
    "        verbose = 50\n",
    "\n",
    "    )\n",
    "\n",
    "    \n",
    "    #val predict\n",
    "    best_rounds = clf.best_iteration_\n",
    "    #best_auc = clf.best_score_['valid_0']['auc']\n",
    "    \n",
    "    \n",
    "    val_pred = clf.predict_proba(val_x)[:, 1]\n",
    "    \n",
    "    df_oof['{}_prob'.format(ycol)] = val_pred\n",
    "    \n",
    "    uAUC_score = uAUC(df_oof[ycol].values,df_oof['{}_prob'.format(ycol)].values)\n",
    "    \n",
    "    \n",
    "\n",
    "    df_importance = pd.DataFrame({\n",
    "            'column': used_feat,\n",
    "            'importance': clf.feature_importances_,\n",
    "        })\n",
    "    df_importance_list.append(df_importance)\n",
    "    \n",
    "    print('uAUC_score',uAUC_score)\n",
    "    print(best_rounds,)\n",
    "    best_rounds_list.append(best_rounds)\n",
    "    \n",
    "    del clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "251"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[6404,6329,7219,6997]\n",
    "#[0.6406,0.6318,0.7228,0.7076]\n",
    "\n",
    "#[1063,693,575,251]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>userid</td>\n",
       "      <td>17263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>authorid</td>\n",
       "      <td>4964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>feedid</td>\n",
       "      <td>3730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>manual_keword</td>\n",
       "      <td>1072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bgm_singer_id</td>\n",
       "      <td>1035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bgm_song_id</td>\n",
       "      <td>942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>manual_tag</td>\n",
       "      <td>447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>user_manual_keword_nunique</td>\n",
       "      <td>272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>device</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>userid_count</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>authorid_count</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>user_manual_tag_nunique</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>user_feedid_nunique</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>feedid_count</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>user_authorid_nunique</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>feedid_user_nunique</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>user_videoplayseconds_nunique</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>description_countvec_2</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>asr_countvec_3</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>asr_tfidf_3</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>description_tfidf_2</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>manual_keword_count</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>description_tfidf_3</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>asr_countvec_1</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>user_bgm_song_id_nunique</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>ocr_countvec_2</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>description_countvec_3</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>asr_tfidf_2</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>description_tfidf_1</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>videoplayseconds_count</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>description_countvec_1</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>asr_countvec_2</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>authorid_user_nunique</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>videoplayseconds</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>asr_tfidf_0</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>user_bgm_singer_id_nunique</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>ocr_tfidf_3</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>bgm_singer_id_count</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>ocr_countvec_3</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>videoplayseconds_user_nunique</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>description_tfidf_0</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>ocr_tfidf_1</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>ocr_tfidf_0</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>description_countvec_0</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>manual_tag_count</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>asr_tfidf_1</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>manual_keword_user_nunique</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>ocr_tfidf_2</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>bgm_song_id_count</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>asr_countvec_0</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>ocr_countvec_0</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>ocr_countvec_1</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>manual_tag_user_nunique</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>userid_authorid_feedid_prev_7day_stay_mean</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>bgm_song_id_user_nunique</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>bgm_singer_id_user_nunique</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>userid_authorid_feedid_prev_7day_read_comment_...</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>userid_authorid_feedid_prev_3day_play_mean</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>userid_authorid_feedid_prev_1day_play_mean</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>userid_authorid_feedid_prev_1day_comment_ratio</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                column  importance\n",
       "0                                               userid       17263\n",
       "3                                             authorid        4964\n",
       "1                                               feedid        3730\n",
       "58                                       manual_keword        1072\n",
       "6                                        bgm_singer_id        1035\n",
       "5                                          bgm_song_id         942\n",
       "59                                          manual_tag         447\n",
       "102                         user_manual_keword_nunique         272\n",
       "2                                               device         169\n",
       "84                                        userid_count         150\n",
       "86                                      authorid_count         150\n",
       "104                            user_manual_tag_nunique         137\n",
       "92                                 user_feedid_nunique         129\n",
       "85                                        feedid_count         126\n",
       "94                               user_authorid_nunique         118\n",
       "93                                 feedid_user_nunique         116\n",
       "100                      user_videoplayseconds_nunique         112\n",
       "66                              description_countvec_2          72\n",
       "83                                      asr_countvec_3          71\n",
       "79                                         asr_tfidf_3          67\n",
       "62                                 description_tfidf_2          62\n",
       "90                                 manual_keword_count          61\n",
       "63                                 description_tfidf_3          61\n",
       "81                                      asr_countvec_1          60\n",
       "96                            user_bgm_song_id_nunique          56\n",
       "74                                      ocr_countvec_2          55\n",
       "67                              description_countvec_3          54\n",
       "78                                         asr_tfidf_2          54\n",
       "61                                 description_tfidf_1          53\n",
       "89                              videoplayseconds_count          52\n",
       "65                              description_countvec_1          52\n",
       "82                                      asr_countvec_2          50\n",
       "95                               authorid_user_nunique          49\n",
       "4                                     videoplayseconds          48\n",
       "76                                         asr_tfidf_0          48\n",
       "98                          user_bgm_singer_id_nunique          47\n",
       "71                                         ocr_tfidf_3          47\n",
       "88                                 bgm_singer_id_count          46\n",
       "75                                      ocr_countvec_3          45\n",
       "101                      videoplayseconds_user_nunique          45\n",
       "60                                 description_tfidf_0          44\n",
       "69                                         ocr_tfidf_1          43\n",
       "68                                         ocr_tfidf_0          42\n",
       "64                              description_countvec_0          41\n",
       "91                                    manual_tag_count          41\n",
       "77                                         asr_tfidf_1          40\n",
       "103                         manual_keword_user_nunique          39\n",
       "70                                         ocr_tfidf_2          38\n",
       "87                                   bgm_song_id_count          36\n",
       "80                                      asr_countvec_0          30\n",
       "72                                      ocr_countvec_0          29\n",
       "73                                      ocr_countvec_1          27\n",
       "105                            manual_tag_user_nunique          26\n",
       "42          userid_authorid_feedid_prev_7day_stay_mean          26\n",
       "97                            bgm_song_id_user_nunique          25\n",
       "99                          bgm_singer_id_user_nunique          23\n",
       "44   userid_authorid_feedid_prev_7day_read_comment_...          22\n",
       "26          userid_authorid_feedid_prev_3day_play_mean          18\n",
       "9           userid_authorid_feedid_prev_1day_play_mean          16\n",
       "13      userid_authorid_feedid_prev_1day_comment_ratio          16"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_importance_list[0].sort_values('importance',ascending = False)[:60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimator_dict = dict(zip(['read_comment', 'like', 'click_avatar', 'forward'],best_rounds_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv(\"wx/wechat_algo_data1/submit_demo_初赛a.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cate_cols = [ 'userid','feedid','authorid','bgm_song_id', 'bgm_singer_id','manual_keword','manual_keword','manual_tag']\n",
    "\n",
    "for ycol in  ['read_comment', 'like', 'click_avatar', 'forward']:\n",
    "\n",
    "    fea_imp_list = []\n",
    "    #train predict\n",
    "    clf = LGBMClassifier(\n",
    "        learning_rate = 0.05,\n",
    "        n_estimators = n_estimator_dict[ycol],\n",
    "        num_leaves = 32,\n",
    "        subsample = 0.9,\n",
    "        colsample_bytree = 0.8,\n",
    "        random_state = 2019,\n",
    "        metric = None\n",
    "    )\n",
    "    #train\n",
    "    clf.fit(\n",
    "        train_df[used_feat],labels[ycol],\n",
    "        eval_set = [(train_df[used_feat],labels[ycol])],\n",
    "        categorical_feature = cate_cols,\n",
    "        verbose = 50\n",
    "    )\n",
    "\n",
    "    res = clf.predict_proba(test_df[used_feat])[:,1]\n",
    "    sub[ycol] = res\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userid</th>\n",
       "      <th>feedid</th>\n",
       "      <th>read_comment</th>\n",
       "      <th>like</th>\n",
       "      <th>click_avatar</th>\n",
       "      <th>forward</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14298</td>\n",
       "      <td>67227</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.004045</td>\n",
       "      <td>0.009690</td>\n",
       "      <td>0.004760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>68356</td>\n",
       "      <td>91864</td>\n",
       "      <td>0.002715</td>\n",
       "      <td>0.001992</td>\n",
       "      <td>0.001203</td>\n",
       "      <td>0.000858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49925</td>\n",
       "      <td>104657</td>\n",
       "      <td>0.015007</td>\n",
       "      <td>0.001351</td>\n",
       "      <td>0.002040</td>\n",
       "      <td>0.003640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60529</td>\n",
       "      <td>23738</td>\n",
       "      <td>0.033674</td>\n",
       "      <td>0.009555</td>\n",
       "      <td>0.010546</td>\n",
       "      <td>0.001543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>131482</td>\n",
       "      <td>69038</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.029216</td>\n",
       "      <td>0.009201</td>\n",
       "      <td>0.000558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421980</th>\n",
       "      <td>133812</td>\n",
       "      <td>56450</td>\n",
       "      <td>0.019016</td>\n",
       "      <td>0.005787</td>\n",
       "      <td>0.003526</td>\n",
       "      <td>0.000932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421981</th>\n",
       "      <td>231669</td>\n",
       "      <td>76501</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.139555</td>\n",
       "      <td>0.003746</td>\n",
       "      <td>0.001096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421982</th>\n",
       "      <td>179168</td>\n",
       "      <td>70550</td>\n",
       "      <td>0.025822</td>\n",
       "      <td>0.026078</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>0.001916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421983</th>\n",
       "      <td>92546</td>\n",
       "      <td>49432</td>\n",
       "      <td>0.013522</td>\n",
       "      <td>0.012677</td>\n",
       "      <td>0.002055</td>\n",
       "      <td>0.000202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421984</th>\n",
       "      <td>205434</td>\n",
       "      <td>2109</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.155215</td>\n",
       "      <td>0.003296</td>\n",
       "      <td>0.004586</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>421985 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        userid  feedid  read_comment      like  click_avatar   forward\n",
       "0        14298   67227      0.000007  0.004045      0.009690  0.004760\n",
       "1        68356   91864      0.002715  0.001992      0.001203  0.000858\n",
       "2        49925  104657      0.015007  0.001351      0.002040  0.003640\n",
       "3        60529   23738      0.033674  0.009555      0.010546  0.001543\n",
       "4       131482   69038      0.000003  0.029216      0.009201  0.000558\n",
       "...        ...     ...           ...       ...           ...       ...\n",
       "421980  133812   56450      0.019016  0.005787      0.003526  0.000932\n",
       "421981  231669   76501      0.000006  0.139555      0.003746  0.001096\n",
       "421982  179168   70550      0.025822  0.026078      0.001700  0.001916\n",
       "421983   92546   49432      0.013522  0.012677      0.002055  0.000202\n",
       "421984  205434    2109      0.000017  0.155215      0.003296  0.004586\n",
       "\n",
       "[421985 rows x 6 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('baseline.csv',index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_py3",
   "language": "python",
   "name": "conda_tensorflow_py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
